---
pageType: daily
aliases:
  - 2025-08-06
created: " 2025-08-06"
---

# [[ August 06, 2025]]
# Notes
---

- https://www.reddit.com/r/ProductManagement/s/6oIbP8pTa9


## [[Style Home|Style]] roadmap in Q3
 [[Style Home|Photo style]] is next. 

### [[Style Home|Photo styles]]

[[Style Home|Photo styles]] are more complex than icons and design assets given the richness and complexity of photos. Not only are there considerations about the image, like it's size, aspect ratio, if it's noisy or free of visible grain, or wether it's in [[Style Home|color]] or black and white, but there are also compositional considerations. 

We should consider training for these things in two segments or layers: **technical** and **Compositional**. 
- Technical 
	- Aspect ratio
	- [[Style Home|color]] vs. B/w
	- Exposure 
		- brightness
		- contrast
	- [[Style Home|Color]] 
		- Temperature 
		- Saturation
		- tone 
	- Texture & noise 
	- Blur
		- Motion blur 
		- Depth of Field
- Compositional 
	- Composition type
		- Rule of 3rds
		- 5ths
		- Golden ratio
		- Golden spiral 
		- Diagonals
		- center
		- Frame within Frame
	- subject placement 


**Wikis**
- https://wiki.corp.adobe.com/pages/viewpage.action?pageId=3103700738
- https://wiki.corp.adobe.com/display/photo/Aesthetics+Model+in+Stack+Leader+Evaluation
- https://wiki.corp.adobe.com/pages/viewpage.action?pageId=3319103137


# Meetings 
---

## [[Lr Home|Lr]] agentic Search #meetings 

Max is the PM for the creative assistant. Jeffry andrew is the right person to talk to. 

**Lr agent**
Current feature in test is "Dynamic sky". AI agent decides what the sky needs and then does it. Currently in pre-release. 

![[Screenshot 2025-08-06 at 13.43.30.png]]

Next is generative preset "suggested edits": 
![[Screenshot 2025-08-06 at 13.47.30 1.png]]
![[Screenshot 2025-08-06 at 13.47.34 1.png]]

There's also an "organizational agent"
Culling on import and catalog management 



## [[Acrobat]] AMA Leads #meetings 

We're not going to re-use the I2A model from the [[express]] agent. 
Internal beta on Aug 20th

## [[Recommendations Home|Recs]] Standup #meetings 

**[[Style Home|Style]]**
- Balancing relevance with [[Style Home|style]] signal
	- computing the recall off line for all CKG intents 
	- We can't always calculate the recall size

**[[Acrobat|PDF recs]] [[Multi-Language 2025|multilanguage]]**
- Using [[AdobeOne V2]] or machine translation for [[Multi-Language 2025|multi-language]] in the short term
- [[Intent AI Home|MINT]] in the long term

## Anuj [[Lr Home|Lr]] Analytics #meetings/1x1 

The Lr team has [outlined a spec](https://app.amplitude.com/analytics/adobe/dashboard/6be35a0y) for the analytics. 
- what is a token remove
	- what is a search session, when is something considered a iteration search
- Missing 
	- Position clicked 
	- AssetID

All this captured data will end up in databricks. 
- Dashboard in powerBI

The data be cleaned and migrated from databricks will reside in redshift or S3. 

Could they give us some mock data in databricks so we can start working on dashboarding with this arch. 

Clarifying the actual rollout with Sanchit and the client team. 
## [[Brian Eriksson|Brian]] #meetings/1x1 

**[[Photoshop]] Tool Recs**
Vipul's premise: 
- if you select a foreground asset vs a background asset would we recommend different tools
Bringing ritu in here: 
- The relationship between clicks and tools is thin
- Can we actaluy learn this
- Is this a unique value for in SDC/Ps
- Do creators want this 


**Pushing [[Style Home|style]] into [[express]] & [[pdf2pres]]** 

pdf2pres is mainstage at MAX25

Taking a wall of text PDF doc, and making an "image + text column" slide deck. 
They want stylistic similarity across the slide

![[Screenshot 2025-08-06 at 13.28.03.png]]



## [[Subhajit]]'s Search Lessons Learned #meetings/org 

**Context & Personalization Foundation**

  Amazon's search system heavily emphasizes context building before
  processing queries. Key components include location, language
  preferences, and user history categorized into long-term memory
  (multi-year purchase history) and working memory (current session
  activities). Notably, Amazon recently shifted to personalizing search
  results based on past purchase behavior - a significant departure from
  their previous non-personalized approach.

  The challenge lies in representing history accurately for downstream
  systems. Engineers must balance between sending raw product IDs versus
  detailed information, while managing payload size to prevent latency
  issues. For personalization, Amazon uses retrieval-augmented generation
  (RAG) to filter user history based on current queries, avoiding noise
  injection.

  **[[Autocomplete]] & Query Processing**

  Amazon's unified autocomplete model handles both on-focus suggestions
  (when search bar is focused) and prefix-based suggestions (as users
  type). The process involves candidate generation followed by ranking to
  maximize user acceptance rates. Despite experimenting with extreme
  classification treating each completion as a separate class, this
  approach yielded no significant improvements.

  Critical metrics include offer rate (fraction of unique prefixes
  receiving suggestions) and acceptance rate (fraction of accepted
  suggestions), all operating under stringent sub-10 millisecond latency
  constraints. The system functions as a bandit optimization problem -
  careful training is essential as poor training quickly degrades
  performance.

  **Query Understanding & Classification**

  Query specificity is measured using click entropy - broad queries show
  higher entropy with diverse product clicks (4+ products), while specific
  queries concentrate on 1-2 products. Amazon models query-to-category
  affinities using multiple taxonomies, similar to Adobe's [[Core Affinity Framework|CAF]] system, but
  with their browse taxonomy structure.

  Named Entity Recognition ([[NER & SRL|NER]]) uses both weakly-labeled datasets and
  human-labeled data with span identification, employing CRF-based
  extractors. This enables different goal-setting based on query types and
  improves overall relevance.

  **Matching & Behavioral Signals**

  Lexical matching relies on product metadata fields but faces keyword
  stuffing challenges, prompting ongoing catalog cleanup projects.
  Behavioral signals include stored purchase logs, though sparsity remains
  challenging. Amazon uses query reformulations and order-independent
  matching to improve results.

  The company has made significant investments in semantic matching using
  bi-encoder models, with an experimental side-loading stack enabling rapid
   experimentation. Future developments focus on integrating semantic
  matching with ranking systems while simplifying overall architecture.

  This comprehensive approach demonstrates Amazon's systematic methodology
  for building context-aware, personalized search experiences at scale.
