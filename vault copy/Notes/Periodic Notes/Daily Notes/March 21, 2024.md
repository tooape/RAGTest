---
pageType: dailyNote
publish: false
aliases:
  - 03.21.2024
created: "3.21.2024"
---
# Notes
---
Brain dump 

Sanats direct to other hierarchies strategy 
- need to evaluate the signal gained there
	- Write use cases 
- Connect to the L0 redfinition stuff 

Roadmap for contextual 
- How will the queries improve 
- beyond april 

Eval 

## Contextual query thoughts
Everything is ultimately an info retrieval problem. We need to look for the most specific understanding we can 

> **Diverging Exploration** Suppose a user gave an image of a poodle in front of the empire state building. When we extract understanding here we might end up with nodes like `poodle, Empire State Building` and a user will want to explore things related to these in different directions. For insance they may be more interested in seeing things related to "Poodles in big cities" or "dogs in NYC". In some instances they may explore both and arrive at "pets in big cities". This branching 

The value of looking at different L0s will vary by use case: 
- Artemis might care more about scene object
- Template contextualization may be more interested in the design task and creative intent 

**how do we evaluate the signal gains by looking down a given hierarchy vs another?**

**Use Case 1 - Template context**
Contextualization of elements 

**Use Case 2 - [[CPT]]**
The captions use case

**Use Case 3 - Artemis**
Understanding style or something 

**use Case 4 - Home screen**
Quick action 
topical ordering 

Inference modeling is the engine here. The tags and assets and embeddings returned are what connects what we have and what the user wants. 

The graph is a means of creating a finite space for structured exploration around these concepts as an information map. 


# Meetings 
---

