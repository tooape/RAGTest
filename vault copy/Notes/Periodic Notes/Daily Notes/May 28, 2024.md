---
pageType: dailyNote
publish: false
aliases:
  - 05.28.2024
  - 5.28.2024
created: "5.28.2024"
---
# Notes
---

Declared meeting bankruptcy and canceled all my meetings and pretended to be sick on slack.

- [x] [Review UI mocks](https://www.figma.com/proto/mu28BlP2bhWZ73VZ3uTiXs/contextual-recommendations?node-id=73-39498&t=mBD6wu6yUldbXram-0&scaling=contain&starting-point-node-id=73%3A39498)

## DME taxonomy notes
![[IMG_4785.jpg|800]]

## Problem
>We want to take the burden off the user and let them just type what they have in their mind and we figure out what's the best content categories to serve their needs - search, generate or both

We need a few structures for this: 
- **Tasks the user might be performing in a given moment** 
	- assetSearch 
	- fileSearch 
	- edit 
	- create 
	- ...
- **Ecosystem**  
	- Different products
		- Stock 
		- [[Firefly]] 
		- [[Express]]
		- Photoshop
		- ...
	- Account 
	- helpX
	- ...
- [[Intent AI Home|CKG]]'s **other hierarchies for things like Element types, etc**
	- Elements 
		- Image
		- Video
		- Template
		- ... 
	- Design Task 
		- Poster
		- Reel
		- Presentation 
		- ...





I2A use cases: 


## Roadmap for the rest of contextualization 

### If we're the long pole
We'd most likely be the long pole only in a situation where the content/design teams felt like our results weren't good enough.
**Quantify with them what good enough is**
- Testing wiki 
	- have them give us some templates to test, send the results, get feedback now 

### If they are 
push for more [[Style Home|style]] cohesion stuff 


This means our roadmap for Q3 is... 
1. Results & query strategy 
2. Visual Cohesion 

