---
pageType: dailyNote
aliases:
  - "4.10.2025"
created: "4.10.2025"
---
# Notes
---

- Chat with Nandaja: 
	- getting the bruth force hybrid search working quickly.
	- Getting discovery hub ready for more spesific evals



[[Lr Home|Lr]] prod account
Prod Account Details  
- Email: [slohia+prod_semantic_search_1@adobetest.com](mailto:slohia+prod_semantic_search_1@adobetest.com)
- Password: Adobe#123


```
I need to analyze some data. First I will describe the context for the data, then I will outline the task I would like you to complete. <About the data> The attached spreadsheet is collected feedback from a series of query analysis from various participants to find the best ranking strategy for an AI search project in Lightroom. The test was conducted by showing two results lists side by side for any query string the participant entered. The user was then asked to choose if the left column's strategy was better, or the right column's strategy. The user may also select that both, or neither query strategy was useful. The user was able to freely select from a list of available queries strategies which column would use what strategy. I need to analyze this data. It has 4 columns:  Col A is "queryString" which is the list of query Strings Col B is "user_feedback" which is the participant's preferred query strategy represented as which column they preferred Col C is "leftVariant" the strategy that the user selected to show in the left column Col D is the "rightVariant" which is the strategy the user selected to show in the right column The names of the strategies in the C and D columns may not make sense, but this is ok. Please continue to use the names in these columns as they are written. </About the data> 


<Expected analysis> I would like to understand the most preferred strategy for different lengths of query by token count. Produce a report which outlines which query strategies are best for each length of query up to 4 tokens. Finish this report with a short summary of your findings. </Expected analysis>

<extra instruction> 
1. pay special attention to how you count the tokens, do not make mistakes. 
2. I do not care which strategy was left or right. Please only list the strategies by the number of times they were chosen as the preferred strategy, including times participants said both strategies were relevant.
</extra instruction>

Please take your time, and go step by step in your analysis. Absolute accuracy is required.

```
# Meetings 
---

## [[Tracy King|Tracy]] stock and [[Express]] query for [[Lr Home|Lightroom]] #meetings 

They take everything that comes back for keyword match, and they do an AND, so you have to match all the terms. For 2+ this is very small 
They use [[Intent AI Home|MINT]] and Adobe One emebddings. They take top 200 from this approach. But this is noisy, so only take top 50. 

This forms the "match set". Now all you need to do is rank it. Get a cosine similarity for everything, even on the keyword search. Get the adobeone score for all of them. You can't for some reason getBM25 scores for the stuff which was brought in because of embedding similarity. We're looking at normalizing BM25.

Take the match set, and apply some sort of weighted sum. 

Using the metadata search as a filter not a ranker. 
- talk to david Uvalle about where to run the filter in the search. You have to filter for data or whatever early, and then get the ANN from the embedding search. 

The BM25 and the cosine scores aren't interpreteable, you can't put a hard threshold. So you have to choose the default very well. 

This is mostly for the 2-4 token query lengths, how do we weight in the different pieces ?
Aesthetics, behavior, recency, tags, embeddings.... 


## [[Recommendations Home|Recommendations]] leads #meetings 

- what are the problems right now with intent, and how is [[CKG 4.0]] solving them 



## Hybrid search #meetings 

1. a call out that type and orientation will be regex based in phase 1 
2. get cherage a list of what we want int type 
	1. raw file extensions? 
	2. Plural
	3. Synonyms 
		1. jpeg
		2. jpg
		3. jpgs
		4. raw / raws 
			1. raf
			2. nef
			3. dng

