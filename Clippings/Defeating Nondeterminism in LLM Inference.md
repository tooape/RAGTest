---
pageTitle: Defeating Nondeterminism in LLM Inference
pageSource: https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/#conclusion
dateCaptured: 2025-09-26T15:20:55-07:00
read: true
---
The article discusses the challenge of achieving reproducible results with large language models (LLMs) due to nondeterminism in inference. While the \\"concurrency + floating point\\" hypothesis is a common explanation, the authors argue it doesn't reveal the full picture.

-  This is caused by individual cores finishing at different times, meaning that cores which finish earlier will have higher floating point precision than those finishing later. 
- The true culprit behind LLM inference nondeterminism is identified as the lack of \\"batch invariance\\" in kernels, meaning results depend on the batch size, which varies nondeterministically with server load.
- The post explains how to achieve batch invariance for RMSNorm, matrix multiplication, and attention kernels by fixing reduction orders and strategies.
- Implementing these batch-invariant kernels on vLLM, the authors demonstrated that 1000 completions from Qwen/Qwen3-235B-A22B-Instruct-2507 (temperature 0) yielded 80 unique completions with default settings, but 100% identical completions with batch-invariant kernels, albeit with a performance overhead.


**Highlights**
> Note that this *is* “run-to-run deterministic.” If you run the script multiple times, it will deterministically return the same result.It is not “hardware/software version invariant” — your GPU/PyTorch version may return a different value, but it should deterministically return the same value.
> 
> However, when a non-batch-invariant kernel is used as part of a larger inference system, the system can become nondeterministic. When you make a query to an inference endpoint, the amount of load the server is under is effectively “nondeterministic” from the user’s perspective. The load determines the batch size that the kernels are run under, and thus changes the eventual result of each individual request!
> 
> <svg xmlns="http://www.w3.org/2000/svg" width="600" height="250" fill="none" viewBox="0 0 600 250"><style>text{font-family:"GT America"}</style><path fill="#f5f5f5" d="M0 0h600v250H0z"></path><g clip-path="url(#nd_clip0_249_8276-nondeterministic-svg)"><path fill="#fff" d="M0 0h600v250H0z"></path><g filter="url(#nd_filter0_f_249_8276-nondeterministic-svg)"><rect width="222" height="238" x="252" y="6" fill="#faf9d3" rx="4"></rect></g><g filter="url(#nd_filter1_f_249_8276-nondeterministic-svg)"><rect width="247" height="91" x="9" y="153" fill="#faf9d3" rx="4"></rect></g><g filter="url(#nd_filter2_f_249_8276-nondeterministic-svg)"><rect width="166" height="163" x="280" y="53" fill="#e3eeb0" rx="4"></rect></g><g filter="url(#nd_filter3_d_249_8276-nondeterministic-svg)"><rect width="82" height="82" x="322" y="95" fill="#fff" rx="4" shape-rendering="crispEdges"></rect><rect width="83" height="83" x="321.5" y="94.5" stroke="#000" stroke-opacity=".2" rx="4.5" shape-rendering="crispEdges"></rect><text xml:space="preserve" fill="#393939" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="342" y="141.565">Model</tspan></text></g><text xml:space="preserve" fill="#5a850c" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="290" y="74.065">Deterministic</tspan></text><text xml:space="preserve" fill="#9c960a" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="262" y="27.065">Nondeterministic</tspan></text><g filter="url(#nd_filter4_d_249_8276-nondeterministic-svg)"><rect width="115" height="35" x="78" y="56" fill="#fff" rx="4" shape-rendering="crispEdges"></rect><rect width="116" height="36" x="77.5" y="55.5" stroke="#000" stroke-opacity=".2" rx="4.5" shape-rendering="crispEdges"></rect><text xml:space="preserve" fill="#393939" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="88" y="79.065">User requests</tspan></text></g><g filter="url(#nd_filter5_d_249_8276-nondeterministic-svg)"><rect width="156" height="35" x="37" y="181" fill="#fff" rx="4" shape-rendering="crispEdges"></rect><rect width="157" height="36" x="36.5" y="180.5" stroke="#000" stroke-opacity=".2" rx="4.5" shape-rendering="crispEdges"></rect><text xml:space="preserve" fill="#393939" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="47" y="204.065">Other user requests</tspan></text></g><g filter="url(#nd_filter6_d_249_8276-nondeterministic-svg)"><rect width="69" height="35" x="517" y="119" fill="#fff" rx="4" shape-rendering="crispEdges"></rect><rect width="70" height="36" x="516.5" y="118.5" stroke="#000" stroke-opacity=".2" rx="4.5" shape-rendering="crispEdges"></rect><text xml:space="preserve" fill="#393939" font-family="GT America" font-size="15" letter-spacing="0em" style="white-space:pre"><tspan x="527" y="142.065">Output</tspan></text></g><path fill="#000" fill-opacity=".5" d="M507.354 136.354a.5.5 0 0 0 0-.708l-3.182-3.182a.502.502 0 0 0-.708.708l2.829 2.828-2.829 2.828a.502.502 0 0 0 .708.708zM413 136v.5h94v-1h-94z"></path><path fill="#000" fill-opacity=".5" d="M218.54 73.514c5.548.28 9.96 4.868 9.96 10.486v42a9.5 9.5 0 0 0 9.5 9.5h72.793l-2.328-2.328a.5.5 0 0 1 .707-.707l3.182 3.181a.5.5 0 0 1 0 .708l-3.182 3.181a.5.5 0 0 1-.707-.707l2.328-2.328H238a9.5 9.5 0 0 0-9.5 9.5v43.5c0 5.799-4.701 10.5-10.5 10.5h-14.5v-1H218a9.5 9.5 0 0 0 9.5-9.5V146c0-4.681 3.063-8.645 7.294-10-4.231-1.355-7.294-5.319-7.294-10V84a9.5 9.5 0 0 0-9.011-9.487L218 74.5h-15v-1h15z"></path></g><defs><filter id="nd_filter0_f_249_8276-nondeterministic-svg" width="238" height="254" x="244" y="-2" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur result="nd_effect1_foregroundBlur_249_8276" stdDeviation="4"></feGaussianBlur></filter><filter id="nd_filter1_f_249_8276-nondeterministic-svg" width="263" height="107" x="1" y="145" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur result="nd_effect2_foregroundBlur_249_8276" stdDeviation="4"></feGaussianBlur></filter><filter id="nd_filter2_f_249_8276-nondeterministic-svg" width="182" height="179" x="272" y="45" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur result="nd_effect3_foregroundBlur_249_8276" stdDeviation="4"></feGaussianBlur></filter><filter id="nd_filter3_d_249_8276-nondeterministic-svg" width="92" height="92" x="317" y="92" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="2"></feOffset><feGaussianBlur stdDeviation="2"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.08 0"></feColorMatrix><feBlend in2="BackgroundImageFix" result="nd_effect1_dropShadow_249_8276"></feBlend><feBlend in="SourceGraphic" in2="nd_effect1_dropShadow_249_8276" result="shape"></feBlend></filter><filter id="nd_filter4_d_249_8276-nondeterministic-svg" width="125" height="45" x="73" y="53" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="2"></feOffset><feGaussianBlur stdDeviation="2"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.08 0"></feColorMatrix><feBlend in2="BackgroundImageFix" result="nd_effect2_dropShadow_249_8276"></feBlend><feBlend in="SourceGraphic" in2="nd_effect2_dropShadow_249_8276" result="shape"></feBlend></filter><filter id="nd_filter5_d_249_8276-nondeterministic-svg" width="166" height="45" x="32" y="178" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="2"></feOffset><feGaussianBlur stdDeviation="2"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.08 0"></feColorMatrix><feBlend in2="BackgroundImageFix" result="nd_effect3_dropShadow_249_8276"></feBlend><feBlend in="SourceGraphic" in2="nd_effect3_dropShadow_249_8276" result="shape"></feBlend></filter><filter id="nd_filter6_d_249_8276-nondeterministic-svg" width="79" height="45" x="512" y="116" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="2"></feOffset><feGaussianBlur stdDeviation="2"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.08 0"></feColorMatrix><feBlend in2="BackgroundImageFix" result="nd_effect4_dropShadow_249_8276"></feBlend><feBlend in="SourceGraphic" in2="nd_effect4_dropShadow_249_8276" result="shape"></feBlend></filter><clipPath id="nd_clip0_249_8276-nondeterministic-svg"><path fill="#fff" d="M0 0h600v250H0z"></path></clipPath></defs></svg>
> 
> Although the inference server itself can be claimed to be "deterministic", the story is different for an individual user. From the perspective of an individual user, the other concurrent users are not an "input" to the system but rather a nondeterministic property of the system. This makes LLM inference "nondeterministic" from the perspective of each user.
> 
> Permance[#](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/#performance "Link to this section")
> 
> We have not put a significant effort into optimizing the performance of the batch-invariant kernels here. However, let’s run some experiments to verify that our performance remains usable.
> 
> We will set up an API server with one GPU running Qwen-3-8B, and request 1000 sequences with an output length of between 90 and 110.
> 
> Conclusion[#](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/#conclusion "Link to this section")
> 
> Modern software systems contain many layers of abstractions. In machine learning, when we run into nondeterminism and subtle numerical differences it can often be tempting to paper over them. After all, our systems are already “probabilistic”, so what’s wrong with a little more nondeterminism? What’s wrong with bumping up the atol/rtol on the failing unit test? The difference in logprobs between the trainer and the sampler probably isn’t a real bug, right?
> 
> We reject this defeatism. With a little bit of work, we *can* understand the root causes of our nondeterminism and even solve them! We hope that this blog post provides the community with a solid understanding of how to resolve nondeterminism in our inference systems and inspires others to obtain a full understanding of their systems.

